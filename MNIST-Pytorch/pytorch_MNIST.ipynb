{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyP5AbnA1PVRo4ItyWVlQ4lK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install torch torchvision"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OnHpcIZdy23Z","outputId":"b0f61aef-c274-4e43-da58-4edebe7a2bae","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n","  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n"]}]},{"cell_type":"markdown","source":["**Importing Required Libraries**"],"metadata":{"id":"27H1WghsoJCj"}},{"cell_type":"code","source":["import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor"],"metadata":{"id":"pwvDbPlyn8iQ","executionInfo":{"status":"ok","timestamp":1721050874159,"user_tz":-120,"elapsed":7054,"user":{"displayName":"rasika kulkarni","userId":"03367435829375963432"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["**How does this code work** -\n","\n","The lab uses MNIST datasets. The dataset has over 60,000 images of hand written digits. The data will be partitioned between training the AI model and testing the AI model after training.\n","\n","The main steps in this project include:\n","\n","1.Download the MNIST dataset and create a DataLoader for the dataset.\n","\n","2.Define an AI model to recognize a hand written digit.\n","\n","3.Train the defined AI model using training data from the MNIST dataset.\n","\n","4.Test the trained AI model using testing data from the MNIST dataset.\n","\n","5.Evaluate\n"],"metadata":{"id":"RXo2WREosrJo"}},{"cell_type":"markdown","source":["**Download Dataset and Create Data Loader**"],"metadata":{"id":"EBsfSb1oogCU"}},{"cell_type":"code","source":["# Download training data from MNIST datasets.\n","training_data = datasets.MNIST(\n","    root=\"data\",\n","    train=True,\n","    download=True,\n","    transform=ToTensor(),\n",")\n","\n","# Download test data from open datasets.\n","test_data = datasets.MNIST(\n","    root=\"data\",\n","    train=False,\n","    download=True,\n","    transform=ToTensor(),\n",")\n","\n","batch_size = 64\n","\n","# Create data loaders to iterate over data\n","train_dataloader = DataLoader(training_data, batch_size=batch_size)\n","test_dataloader = DataLoader(test_data, batch_size=batch_size)\n","\n","print(\"Training data size:\", len(train_dataloader) * batch_size)\n","print(\"Test data size:\", len(test_dataloader) * batch_size)\n","\n","for X, y in test_dataloader:\n","    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n","    print(f\"Shape of y: {y.shape} {y.dtype}\")\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3rQwuY37oabb","executionInfo":{"status":"ok","timestamp":1721051132068,"user_tz":-120,"elapsed":288,"user":{"displayName":"rasika kulkarni","userId":"03367435829375963432"}},"outputId":"246639dd-52aa-4cfd-d214-ea8ebcf8210a"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Training data size: 60032\n","Test data size: 10048\n","Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n","Shape of y: torch.Size([64]) torch.int64\n"]}]},{"cell_type":"markdown","source":["**Define Model**"],"metadata":{"id":"zuOKQdWJp0K0"}},{"cell_type":"code","source":["# Get device for training.\n","device = torch.device(\n","    \"cuda\" if torch.cuda.is_available()\n","    else \"mps\" if torch.backends.mps.is_available() # Apple Silicon GPU\n","    else \"cpu\"\n",")\n","print(f\"Using {device} device\")\n","\n","# Define model\n","class NeuralNetwork(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_classes):\n","        super().__init__()\n","        self.flatten = nn.Flatten()\n","        self.linear_relu_stack = nn.Sequential(\n","            nn.Linear(input_size, hidden_size),\n","            nn.ReLU(),\n","            nn.Linear(hidden_size, hidden_size),\n","            nn.ReLU(),\n","            nn.Linear(hidden_size, num_classes)\n","        )\n","\n","    def forward(self, image_tensor):\n","        image_tensor = self.flatten(image_tensor)\n","        logits = self.linear_relu_stack(image_tensor)\n","        return logits\n","\n","input_size = 28*28\n","hidden_size = 512\n","num_classes = 10\n","\n","model = NeuralNetwork(input_size, hidden_size, num_classes).to(device)\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r-GN8jLGpqHk","executionInfo":{"status":"ok","timestamp":1721051297671,"user_tz":-120,"elapsed":301,"user":{"displayName":"rasika kulkarni","userId":"03367435829375963432"}},"outputId":"1f4e9263-f695-4be8-c2ab-6be7bd853de3"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Using cuda device\n","NeuralNetwork(\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (linear_relu_stack): Sequential(\n","    (0): Linear(in_features=784, out_features=512, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=512, out_features=512, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=512, out_features=10, bias=True)\n","  )\n",")\n"]}]},{"cell_type":"markdown","source":["Training the loop"],"metadata":{"id":"vHZpE_DJrPHk"}},{"cell_type":"code","source":["# Define our learning rate, loss function and optimizer\n","learning_rate = 1e-3 # 0.001\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# Let's define our training function\n","def train(dataloader, model, loss_fn, optimizer):\n","    size = len(dataloader.dataset)\n","    model.train()\n","\n","    for batch_num, (X, y) in enumerate(dataloader):\n","        X, y = X.to(device), y.to(device)\n","\n","        # Forward pass to compute prediction\n","        pred = model(X)\n","        # Compute prediction error using loss function\n","        loss = loss_fn(pred, y)\n","\n","        # Backward pass\n","        optimizer.zero_grad() # zero any previous gradient calculations\n","        loss.backward() # calculate gradient\n","        optimizer.step() # update model parameters\n","\n","        if batch_num > 0 and batch_num % 100 == 0:\n","            loss, current = loss.item(), batch_num * len(X)\n","            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"],"metadata":{"id":"0zPNCVvvrRkU","executionInfo":{"status":"ok","timestamp":1721051721942,"user_tz":-120,"elapsed":343,"user":{"displayName":"rasika kulkarni","userId":"03367435829375963432"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["Testing the loop"],"metadata":{"id":"vMftP68grZ2I"}},{"cell_type":"code","source":["# Our test function\n","def test(dataloader, model, loss_fn):\n","    size = len(dataloader.dataset)\n","    num_batches = len(dataloader)\n","    model.eval()\n","    test_loss, correct = 0, 0\n","    for X, y in dataloader:\n","        X, y = X.to(device), y.to(device)\n","        pred = model(X)\n","        test_loss += loss_fn(pred, y).item()\n","        correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n","    test_loss /= num_batches\n","    correct /= size\n","    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"],"metadata":{"id":"MMGNQAGvrcVQ","executionInfo":{"status":"ok","timestamp":1721051764479,"user_tz":-120,"elapsed":324,"user":{"displayName":"rasika kulkarni","userId":"03367435829375963432"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["**Train the Model**"],"metadata":{"id":"YxeqYgL1rjw6"}},{"cell_type":"code","source":["# Let's run training\n","epochs = 5\n","for t in range(epochs):\n","    print(f\"Epoch {t+1}\\n-------------------------------\")\n","    train(train_dataloader, model, loss_fn, optimizer)\n","    test(test_dataloader, model, loss_fn)\n","print(\"Done!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rxxzXrQgrnV5","executionInfo":{"status":"ok","timestamp":1721051852620,"user_tz":-120,"elapsed":42869,"user":{"displayName":"rasika kulkarni","userId":"03367435829375963432"}},"outputId":"56dee0d2-1f77-4dd9-d649-0df9a0039596"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1\n","-------------------------------\n","loss: 0.288566  [ 6400/60000]\n","loss: 0.200262  [12800/60000]\n","loss: 0.249023  [19200/60000]\n","loss: 0.139102  [25600/60000]\n","loss: 0.391990  [32000/60000]\n","loss: 0.133330  [38400/60000]\n","loss: 0.189181  [44800/60000]\n","loss: 0.301556  [51200/60000]\n","loss: 0.187745  [57600/60000]\n","Test Error: \n"," Accuracy: 95.5%, Avg loss: 0.143093 \n","\n","Epoch 2\n","-------------------------------\n","loss: 0.076868  [ 6400/60000]\n","loss: 0.092410  [12800/60000]\n","loss: 0.074797  [19200/60000]\n","loss: 0.037189  [25600/60000]\n","loss: 0.141107  [32000/60000]\n","loss: 0.059486  [38400/60000]\n","loss: 0.117257  [44800/60000]\n","loss: 0.109946  [51200/60000]\n","loss: 0.143648  [57600/60000]\n","Test Error: \n"," Accuracy: 96.5%, Avg loss: 0.114711 \n","\n","Epoch 3\n","-------------------------------\n","loss: 0.076396  [ 6400/60000]\n","loss: 0.083997  [12800/60000]\n","loss: 0.148650  [19200/60000]\n","loss: 0.044938  [25600/60000]\n","loss: 0.093138  [32000/60000]\n","loss: 0.038942  [38400/60000]\n","loss: 0.083999  [44800/60000]\n","loss: 0.097805  [51200/60000]\n","loss: 0.052852  [57600/60000]\n","Test Error: \n"," Accuracy: 97.3%, Avg loss: 0.093692 \n","\n","Epoch 4\n","-------------------------------\n","loss: 0.034610  [ 6400/60000]\n","loss: 0.032834  [12800/60000]\n","loss: 0.081278  [19200/60000]\n","loss: 0.060735  [25600/60000]\n","loss: 0.067422  [32000/60000]\n","loss: 0.030366  [38400/60000]\n","loss: 0.040324  [44800/60000]\n","loss: 0.119719  [51200/60000]\n","loss: 0.028733  [57600/60000]\n","Test Error: \n"," Accuracy: 97.3%, Avg loss: 0.102108 \n","\n","Epoch 5\n","-------------------------------\n","loss: 0.008459  [ 6400/60000]\n","loss: 0.052674  [12800/60000]\n","loss: 0.026475  [19200/60000]\n","loss: 0.006922  [25600/60000]\n","loss: 0.045303  [32000/60000]\n","loss: 0.011481  [38400/60000]\n","loss: 0.054409  [44800/60000]\n","loss: 0.041939  [51200/60000]\n","loss: 0.027915  [57600/60000]\n","Test Error: \n"," Accuracy: 97.2%, Avg loss: 0.111360 \n","\n","Done!\n"]}]},{"cell_type":"markdown","source":["Save the model"],"metadata":{"id":"kMCjJ3QDr35d"}},{"cell_type":"code","source":["# Save our model parameters\n","torch.save(model.state_dict(), \"ml_with_pytorch_model.pth\")\n","print(\"Saved PyTorch Model State to ml_with_pytorch_model.pth\")\n","\n","# Load the saved model parameters into a new instance of the model\n","model = NeuralNetwork(input_size, hidden_size, num_classes).to(device)\n","model.load_state_dict(torch.load(\"ml_with_pytorch_model.pth\"))\n","\n","# Inference using the new model instance\n","model.eval()\n","for i in range(10):\n","    x, y = test_data[i][0], test_data[i][1]\n","\n","    x = x.to(device)\n","    pred = model(x)\n","    predicted, actual = pred[0].argmax(0).item(), y\n","    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fuUc2H_lr6n_","executionInfo":{"status":"ok","timestamp":1721051911145,"user_tz":-120,"elapsed":288,"user":{"displayName":"rasika kulkarni","userId":"03367435829375963432"}},"outputId":"a3f55d6e-0c10-4773-b2bd-abd279b3c77d"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved PyTorch Model State to ml_with_pytorch_model.pth\n","Predicted: \"7\", Actual: \"7\"\n","Predicted: \"2\", Actual: \"2\"\n","Predicted: \"1\", Actual: \"1\"\n","Predicted: \"0\", Actual: \"0\"\n","Predicted: \"4\", Actual: \"4\"\n","Predicted: \"1\", Actual: \"1\"\n","Predicted: \"4\", Actual: \"4\"\n","Predicted: \"9\", Actual: \"9\"\n","Predicted: \"5\", Actual: \"5\"\n","Predicted: \"9\", Actual: \"9\"\n"]}]}]}